# Adaptive Context Compression RAG System - Architecture Document

## Table of Contents
1. [Executive Summary](#executive-summary)
2. [Architecture Selection & Justification](#architecture-selection--justification)
3. [System Architecture Overview](#system-architecture-overview)
4. [Component Architecture](#component-architecture)
5. [Data Flow Architecture](#data-flow-architecture)
6. [Deployment Architecture](#deployment-architecture)
7. [Use Cases](#use-cases)
8. [Class Design](#class-design)
9. [Sequence Diagrams](#sequence-diagrams)
10. [Technology Stack Justification](#technology-stack-justification)
11. [Scalability & Performance](#scalability--performance)
12. [Security Considerations](#security-considerations)
13. [Future Enhancements](#future-enhancements)

---

## 1. Executive Summary

### Project Overview
The Adaptive Context Compression RAG (Retrieval-Augmented Generation) system is a research-oriented application designed to solve the critical problem of context window limitations in Large Language Models (LLMs) when processing technical documents such as research papers and API documentation.

### Problem Statement
- Technical documents often exceed LLM context limits (4K-32K tokens)
- Traditional RAG systems use fixed chunking, breaking semantic coherence
- Retrieving too much context wastes tokens and increases costs
- Retrieving too little context leads to hallucinations and incomplete answers

### Solution Approach
Our system implements **intent-aware adaptive compression** that:
1. Detects the user's query intent (METHOD, RESULT, API_USAGE, DEFINITION, COMPARISON)
2. Retrieves semantically relevant document chunks
3. Selects high-signal evidence at sentence-level granularity
4. Enforces strict token budgets while preserving answer quality
5. Generates grounded, citation-backed answers

### Key Metrics
- **45% average token reduction** across test queries
- **92% answer correctness** maintained vs baseline
- **Token budget compliance**: 100% (hard constraint enforcement)
- **Support for 5 intent types** with specialized compression strategies

---

## 2. Architecture Selection & Justification

### Chosen Architecture: **Modular Monolithic Architecture**

#### Rationale for Monolithic Approach

After careful analysis of our requirements, we selected a **Modular Monolithic Architecture** over microservices, event-driven, or serverless architectures. Here's our detailed justification:

#### âœ… Why Monolithic is Optimal for Our Use Case

**1. Research & Development Focus**
- This is a research project requiring rapid iteration and experimentation
- Monolithic architecture allows quick changes without managing distributed system complexity
- Easier debugging and tracing through the entire pipeline
- Single codebase simplifies version control and reproducibility

**2. Sequential Pipeline Nature**
- Our RAG pipeline is inherently sequential: Ingestion â†’ Indexing â†’ Retrieval â†’ Compression â†’ Generation
- Each stage depends on the previous stage's output
- No benefit from distributed processing for single-query execution
- Low latency requirements favor in-process communication over network calls

**3. Shared State Requirements**
- FAISS vector index is loaded in memory for fast similarity search
- Embedding model (Sentence-BERT) is pre-loaded to avoid repeated initialization
- Document metadata is tightly coupled with vector embeddings
- Monolithic architecture enables efficient memory sharing

**4. Development & Deployment Simplicity**
- Single deployment artifact (Python application)
- No need for inter-service communication protocols (REST, gRPC, message queues)
- Simplified dependency management
- Lower operational overhead for a research team

**5. Performance Considerations**
- In-process function calls (nanoseconds) vs network calls (milliseconds)
- No serialization/deserialization overhead
- Efficient memory access patterns
- Critical for real-time query processing

#### âŒ Why We Rejected Other Architectures

**Microservices Architecture - Not Suitable Because:**
- Overhead of managing multiple services outweighs benefits
- Network latency would slow down the sequential pipeline
- Unnecessary complexity for a single-team research project
- No independent scaling needs (all components scale together)
- Distributed debugging is harder for ML/AI pipelines

**Event-Driven Architecture - Not Suitable Because:**
- Our pipeline is request-response, not event-based
- No asynchronous processing requirements
- Added complexity of message brokers (Kafka, RabbitMQ) unnecessary
- Harder to maintain transactional consistency across pipeline stages

**Serverless Architecture - Not Suitable Because:**
- Cold start latency (1-3 seconds) unacceptable for interactive queries
- Vector index and ML model loading too expensive per invocation
- State management (FAISS index, embeddings) requires persistent compute
- Cost-ineffective for research workloads with frequent testing

#### ğŸ”§ Modular Design Within Monolith

While monolithic, our architecture maintains **high modularity** through:

```
Separation of Concerns:
â”œâ”€â”€ Ingestion Layer    (PDF/HTML extraction, section detection)
â”œâ”€â”€ Indexing Layer     (Chunking, embeddings, vector storage)
â”œâ”€â”€ Retrieval Layer    (Intent detection, similarity search)
â”œâ”€â”€ Compression Layer  (Evidence selection, budget management)
â””â”€â”€ Generation Layer   (LLM integration, answer synthesis)
```

Each layer has:
- **Clear interfaces**: Well-defined function signatures
- **Single responsibility**: Each module handles one concern
- **Loose coupling**: Modules interact through data structures, not direct dependencies
- **High cohesion**: Related functionality grouped together
- **Testability**: Each module can be tested independently

This approach gives us **80% of microservices benefits** (modularity, testability, maintainability) with **20% of the complexity**.

---

## 3. System Architecture Overview

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Streamlit Web Application                        â”‚  â”‚
â”‚  â”‚  - Document Upload Widget                                     â”‚  â”‚
â”‚  â”‚  - Query Input Interface                                      â”‚  â”‚
â”‚  â”‚  - Result Visualization                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION ORCHESTRATION LAYER                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Main RAG Controller                         â”‚  â”‚
â”‚  â”‚  - Pipeline Coordination                                      â”‚  â”‚
â”‚  â”‚  - Session Management                                         â”‚  â”‚
â”‚  â”‚  - Error Handling                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INGESTION    â”‚  â”‚   RETRIEVAL    â”‚  â”‚   GENERATION   â”‚
â”‚     LAYER      â”‚  â”‚     LAYER      â”‚  â”‚     LAYER      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CORE SERVICES LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Document    â”‚  â”‚   Intent     â”‚  â”‚  Evidence    â”‚             â”‚
â”‚  â”‚  Processor   â”‚  â”‚  Detector    â”‚  â”‚  Selector    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Section    â”‚  â”‚  Retriever   â”‚  â”‚   Budget     â”‚             â”‚
â”‚  â”‚  Detector    â”‚  â”‚  (Vector)    â”‚  â”‚  Manager     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Chunker    â”‚  â”‚  Reranker    â”‚  â”‚     LLM      â”‚             â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚   Wrapper    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA PERSISTENCE LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚    FAISS     â”‚  â”‚   Document   â”‚  â”‚   Config     â”‚             â”‚
â”‚  â”‚ Vector Store â”‚  â”‚   Metadata   â”‚  â”‚    Store     â”‚             â”‚
â”‚  â”‚  (In-Memory) â”‚  â”‚   (JSON)     â”‚  â”‚    (YAML)    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EXTERNAL SERVICES LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Google     â”‚  â”‚  Sentence    â”‚  â”‚   PyMuPDF    â”‚             â”‚
â”‚  â”‚   Gemini     â”‚  â”‚ Transformers â”‚  â”‚   (fitz)     â”‚             â”‚
â”‚  â”‚     API      â”‚  â”‚  (Hugging    â”‚  â”‚              â”‚             â”‚
â”‚  â”‚              â”‚  â”‚    Face)     â”‚  â”‚              â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Layers Explained

#### Layer 1: User Interface Layer
- **Technology**: Streamlit (Python-based web framework)
- **Responsibility**: User interaction, file uploads, query input, result display
- **Communication**: Direct Python function calls to orchestration layer

#### Layer 2: Application Orchestration Layer
- **Technology**: Python application logic
- **Responsibility**: Coordinates the RAG pipeline, manages state, handles errors
- **Communication**: Synchronous function calls to core services

#### Layer 3: Core Services Layer
- **Technology**: Python modules with functional programming approach
- **Responsibility**: Business logic for each pipeline stage
- **Communication**: Data structure passing (dictionaries, lists)

#### Layer 4: Data Persistence Layer
- **Technology**: FAISS (in-memory), JSON (file-based), YAML (config)
- **Responsibility**: Vector storage, metadata persistence, configuration
- **Communication**: File I/O and in-memory data structures

#### Layer 5: External Services Layer
- **Technology**: REST APIs, Python libraries
- **Responsibility**: LLM inference, embeddings, document parsing
- **Communication**: HTTP requests (Gemini API), library imports

---

## 4. Component Architecture

### Detailed Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          INGESTION COMPONENTS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  PDF Extractor      â”‚         â”‚  HTML Extractor     â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚ + extract_text()    â”‚         â”‚ + extract()         â”‚            â”‚
â”‚  â”‚   - Uses PyMuPDF    â”‚         â”‚   - BeautifulSoup   â”‚            â”‚
â”‚  â”‚   - Page-by-page    â”‚         â”‚   - DOM parsing     â”‚            â”‚
â”‚  â”‚   - Returns list    â”‚         â”‚   - Not implemented â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚            â”‚                                â”‚                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                         â–¼                                             â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚            â”‚   Section Detector      â”‚                               â”‚
â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â”‚
â”‚            â”‚ + detect_sections()     â”‚                               â”‚
â”‚            â”‚   - Regex patterns      â”‚                               â”‚
â”‚            â”‚   - Academic sections   â”‚                               â”‚
â”‚            â”‚   - Heuristic-based     â”‚                               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          INDEXING COMPONENTS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚      Chunker            â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + chunk_documents()     â”‚                                         â”‚
â”‚  â”‚ + _split_text()         â”‚                                         â”‚
â”‚  â”‚ + _split_sentences()    â”‚                                         â”‚
â”‚  â”‚   - 1000 char chunks    â”‚                                         â”‚
â”‚  â”‚   - Sentence boundary   â”‚                                         â”‚
â”‚  â”‚   - Preserves metadata  â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚      Embedder           â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + generate_embeddings() â”‚                                         â”‚
â”‚  â”‚   - Model: MiniLM-L6-v2 â”‚                                         â”‚
â”‚  â”‚   - Dimension: 384      â”‚                                         â”‚
â”‚  â”‚   - Batch processing    â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚    Vector Store         â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + build_faiss_index()   â”‚                                         â”‚
â”‚  â”‚ + search_index()        â”‚                                         â”‚
â”‚  â”‚   - FAISS IndexFlatL2   â”‚                                         â”‚
â”‚  â”‚   - Exact L2 search     â”‚                                         â”‚
â”‚  â”‚   - In-memory storage   â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RETRIEVAL COMPONENTS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚   Intent Detector       â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + detect_intent()       â”‚                                         â”‚
â”‚  â”‚   - METHOD              â”‚                                         â”‚
â”‚  â”‚   - RESULT              â”‚                                         â”‚
â”‚  â”‚   - API_USAGE           â”‚                                         â”‚
â”‚  â”‚   - DEFINITION          â”‚                                         â”‚
â”‚  â”‚   - COMPARISON          â”‚                                         â”‚
â”‚  â”‚   - Rule-based keywords â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚  Intent-Aware Retriever â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + retrieve_with_intent()â”‚                                         â”‚
â”‚  â”‚ + calculate_bonus()     â”‚                                         â”‚
â”‚  â”‚   - Vector search       â”‚                                         â”‚
â”‚  â”‚   - Section bonuses     â”‚                                         â”‚
â”‚  â”‚   - Re-ranking          â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚      Reranker           â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + rerank()              â”‚                                         â”‚
â”‚  â”‚   - Not implemented     â”‚                                         â”‚
â”‚  â”‚   - Placeholder for     â”‚                                         â”‚
â”‚  â”‚     cross-encoder       â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        COMPRESSION COMPONENTS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚  Evidence Selector      â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + select_evidence()     â”‚                                         â”‚
â”‚  â”‚ + score_sentence()      â”‚                                         â”‚
â”‚  â”‚ + split_sentences()     â”‚                                         â”‚
â”‚  â”‚   - Intent-aware scoringâ”‚                                         â”‚
â”‚  â”‚   - Sentence-level      â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚   Budget Manager        â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + apply_budget()        â”‚                                         â”‚
â”‚  â”‚ + estimate_tokens()     â”‚                                         â”‚
â”‚  â”‚   - Greedy selection    â”‚                                         â”‚
â”‚  â”‚   - Hard limit          â”‚                                         â”‚
â”‚  â”‚   - 4 chars = 1 token   â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚  Context Compressor     â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + compress_context()    â”‚                                         â”‚
â”‚  â”‚   - Orchestrates:       â”‚                                         â”‚
â”‚  â”‚   1. Retrieval          â”‚                                         â”‚
â”‚  â”‚   2. Evidence selection â”‚                                         â”‚
â”‚  â”‚   3. Budget application â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GENERATION COMPONENTS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚      LLM Wrapper        â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + generate_answer()     â”‚                                         â”‚
â”‚  â”‚   - Google Gemini API   â”‚                                         â”‚
â”‚  â”‚   - Model: 2.5-flash    â”‚                                         â”‚
â”‚  â”‚   - Temperature: 0.2    â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚  Answer Generator       â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + generate()            â”‚                                         â”‚
â”‚  â”‚   - Not implemented     â”‚                                         â”‚
â”‚  â”‚   - Placeholder         â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚             â”‚                                                         â”‚
â”‚             â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚   Citation Handler      â”‚                                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                         â”‚
â”‚  â”‚ + extract_citations()   â”‚                                         â”‚
â”‚  â”‚ + check_sufficiency()   â”‚                                         â”‚
â”‚  â”‚ + generate_refusal()    â”‚                                         â”‚
â”‚  â”‚   - Not implemented     â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Interactions

Each component has clear responsibilities:

1. **Ingestion Components**: Transform raw documents into structured text with metadata
2. **Indexing Components**: Convert text into searchable vector representations
3. **Retrieval Components**: Find relevant information based on query semantics and intent
4. **Compression Components**: Reduce context size while preserving high-signal content
5. **Generation Components**: Synthesize final answers using LLM

---

## 5. Data Flow Architecture

### Data Flow Diagram (DFD) - Level 0 (Context Diagram)

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    User     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                     â”‚
                    â–¼                     â–¼
            Upload Document          Ask Question
                    â”‚                     â”‚
                    â”‚                     â”‚
                    â–¼                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
        â”‚    Adaptive RAG Compression System    â”‚
        â”‚                                       â”‚
        â”‚  - Ingests documents                  â”‚
        â”‚  - Detects query intent               â”‚
        â”‚  - Retrieves relevant chunks          â”‚
        â”‚  - Compresses evidence                â”‚
        â”‚  - Generates grounded answers         â”‚
        â”‚                                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Answer + Stats â”‚
              â”‚  - Answer text  â”‚
              â”‚  - Citations    â”‚
              â”‚  - Token usage  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   User   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Diagram - Level 1 (Process Breakdown)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 1. PDF/HTML Document
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P1: INGESTION      â”‚
â”‚  Extract & Section  â”‚
â”‚  Detection          â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 2. Pages with Sections
      â”‚    [{page, section, text}]
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P2: INDEXING       â”‚
â”‚  Chunk & Embed      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 3. Chunks with Embeddings
      â”‚    [{chunk_id, embedding, metadata}]
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D1: VECTOR STORE   â”‚
â”‚  FAISS Index        â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 4. Query from User
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P3: INTENT         â”‚
â”‚  DETECTION          â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 5. Intent Info
      â”‚    {intent, confidence}
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P4: RETRIEVAL      â”‚
â”‚  Vector Search      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 6. Retrieved Chunks
      â”‚    [{rank, score, text, metadata}]
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P5: COMPRESSION    â”‚
â”‚  Evidence Selection â”‚
â”‚  + Budget Mgmt      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 7. Compressed Context
      â”‚    {context, tokens_used, sentences}
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P6: GENERATION     â”‚
â”‚  LLM Answer         â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 8. Final Answer
      â”‚    {answer, citations, stats}
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Diagram - Level 2 (Compression Process Detail)

```
                    Retrieved Chunks
                    from Vector Store
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  P5.1: Split into Sentences      â”‚
        â”‚  - Regex sentence splitting      â”‚
        â”‚  - Preserve metadata             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Sentence List
                     â”‚ [{sentence, page, section}]
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  P5.2: Score Sentences           â”‚
        â”‚  - Apply intent-specific rules   â”‚
        â”‚  - Calculate relevance scores    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Scored Sentences
                     â”‚ [{sentence, score, metadata}]
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  P5.3: Sort by Score             â”‚
        â”‚  - Descending order              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Ranked Sentences
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  P5.4: Apply Token Budget        â”‚
        â”‚  - Greedy selection              â”‚
        â”‚  - Estimate tokens (char/4)      â”‚
        â”‚  - Stop at budget limit          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Selected Sentences
                     â”‚ within budget
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  P5.5: Build Context String      â”‚
        â”‚  - Join with double newlines     â”‚
        â”‚  - Return compressed context     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
                Compressed Context
                to LLM Generation
```

### Data Store Specifications

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D1: FAISS Vector Store (In-Memory)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Type: FAISS IndexFlatL2                                   â”‚
â”‚  Dimension: 384 (from Sentence-BERT)                       â”‚
â”‚  Size: ~4KB per vector (384 floats * 4 bytes + overhead)   â”‚
â”‚  Operations: Add vectors, K-NN search                      â”‚
â”‚  Persistence: Saveable to disk, loaded at startup          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D2: Document Metadata Store (JSON)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Format: JSON array of objects                             â”‚
â”‚  Schema: {chunk_id, page, section, text}                   â”‚
â”‚  Index Alignment: Position matches FAISS index position    â”‚
â”‚  Storage: File system (data/processed/)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D3: Configuration Store (YAML)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Format: YAML                                              â”‚
â”‚  Location: config/default_config.yaml                      â”‚
â”‚  Contents: Model params, token budgets, thresholds         â”‚
â”‚  Loading: At application startup                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Deployment Architecture

### Deployment Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLIENT LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                  Web Browser                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚  â”‚  â”‚        Streamlit UI (React-based)            â”‚      â”‚    â”‚
â”‚  â”‚  â”‚  - File upload widget                        â”‚      â”‚    â”‚
â”‚  â”‚  â”‚  - Query input form                          â”‚      â”‚    â”‚
â”‚  â”‚  â”‚  - Results display                           â”‚      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTP/WebSocket
                           â”‚ (localhost:8501)
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION SERVER                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Streamlit Server (Python)                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚         RAG Application Process                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Ingestion Module                            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - PDF Extractor (PyMuPDF)                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Section Detector                          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Indexing Module                             â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Chunker                                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Embedder (Sentence-BERT)                  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Vector Store (FAISS)                      â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Retrieval Module                            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Intent Detector                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Intent-Aware Retriever                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Compression Module                          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Evidence Selector                         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Budget Manager                            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Generation Module                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - LLM Wrapper                               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Runtime Environment:                                           â”‚
â”‚  - Python 3.9+                                                  â”‚
â”‚  - Virtual Environment (venv/conda)                             â”‚
â”‚  - Memory: ~2-4GB (FAISS index + models)                        â”‚
â”‚  - CPU: Multi-core recommended                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  File System   â”‚  â”‚  File System   â”‚  â”‚   File System   â”‚   â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                 â”‚   â”‚
â”‚  â”‚  data/         â”‚  â”‚  config/       â”‚  â”‚  data/          â”‚   â”‚
â”‚  â”‚  â”œâ”€raw/        â”‚  â”‚  â””â”€default_    â”‚  â”‚  â””â”€vector_db/   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€*.pdf    â”‚  â”‚    config.yaml â”‚  â”‚     â””â”€*.index   â”‚   â”‚
â”‚  â”‚  â””â”€processed/  â”‚  â”‚                â”‚  â”‚                 â”‚   â”‚
â”‚  â”‚     â””â”€*.json   â”‚  â”‚                â”‚  â”‚                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  EXTERNAL SERVICES                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         Google Gemini API (Cloud)                      â”‚    â”‚
â”‚  â”‚  - Endpoint: generativelanguage.googleapis.com         â”‚    â”‚
â”‚  â”‚  - Model: gemini-2.5-flash                             â”‚    â”‚
â”‚  â”‚  - Auth: API Key (environment variable)                â”‚    â”‚
â”‚  â”‚  - Protocol: HTTPS REST API                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Hugging Face Model Hub (Download Only)            â”‚    â”‚
â”‚  â”‚  - Model: sentence-transformers/all-MiniLM-L6-v2       â”‚    â”‚
â”‚  â”‚  - Downloaded to: ~/.cache/huggingface/                â”‚    â”‚
â”‚  â”‚  - Size: ~80MB                                         â”‚    â”‚
â”‚  â”‚  - One-time download, then local inference             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deployment Configurations

#### Development Deployment
```yaml
Environment: Local Machine
Platform: macOS/Linux/Windows
Python: 3.9+
Dependencies: pip install -r requirements.txt
Launch: streamlit run app/streamlit_app.py
Port: 8501 (default Streamlit port)
Data: Local file system
Vector Store: In-memory FAISS
```

#### Production Deployment (Recommended)
```yaml
Environment: Cloud VM (AWS EC2, GCP Compute Engine, Azure VM)
Instance Type: 
  - CPU: 4+ cores
  - RAM: 8GB+ (for FAISS index + models)
  - Storage: 20GB+ SSD
Container: Docker (optional but recommended)
Reverse Proxy: Nginx (for SSL/TLS)
Process Manager: systemd or supervisor
Monitoring: Application logs + resource monitoring
```

#### Docker Deployment
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501
CMD ["streamlit", "run", "app/streamlit_app.py", "--server.port=8501"]
```

### Network Architecture

```
Internet
   â”‚
   â”‚ HTTPS (443)
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Balancer  â”‚  (Optional: for scaling)
â”‚  (Nginx/HAProxy)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ HTTP (8501)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit Application  â”‚
â”‚  (Python Process)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º File System (local)
         â”‚
         â””â”€â”€â–º Google Gemini API (HTTPS)
              (External, Internet)
```

---

## 7. Use Cases

### Use Case Diagram

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                     â”‚
                                    â”‚   Research Student  â”‚
                                    â”‚                     â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                              â”‚                              â”‚
                â–¼                              â–¼                              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Upload         â”‚          â”‚  Ask Question   â”‚          â”‚  View Results   â”‚
      â”‚  Research Paper â”‚          â”‚  About Paper    â”‚          â”‚  & Citations    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                              â”‚
                â”‚                              â”‚
                â”‚                              â–¼
                â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                    â”‚  Detect Query   â”‚
                â”‚                    â”‚  Intent         â”‚
                â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                              â”‚
                â–¼                              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Extract Text   â”‚          â”‚  Retrieve       â”‚
      â”‚  from PDF       â”‚          â”‚  Relevant       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  Chunks         â”‚
                â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼                              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â–¼
      â”‚  Detect         â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Sections       â”‚          â”‚  Compress       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  Context        â”‚
                â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼                              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â–¼
      â”‚  Chunk          â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Document       â”‚          â”‚  Generate       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  Answer with    â”‚
                â”‚                  â”‚  LLM            â”‚
                â–¼                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
      â”‚  Generate       â”‚                     â–¼
      â”‚  Embeddings     â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  Extract        â”‚
                â”‚                  â”‚  Citations      â”‚
                â–¼                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Build Vector   â”‚
      â”‚  Index          â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚
                    â”‚  API Developer   â”‚
                    â”‚                  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Upload API     â”‚ â”‚  Query API      â”‚ â”‚  Get Usage      â”‚
â”‚  Documentation  â”‚ â”‚  Function Usage â”‚ â”‚  Examples       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚
          â”‚                  â”‚
          â”‚                  â–¼
          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        â”‚  Intent:        â”‚
          â”‚        â”‚  API_USAGE      â”‚
          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚
          â”‚                  â–¼
          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        â”‚  Prioritize     â”‚
          â”‚        â”‚  Code Snippets  â”‚
          â”‚        â”‚  & Parameters   â”‚
          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
(Same indexing pipeline as above)
```

### Detailed Use Case Specifications

#### Use Case 1: Upload and Index Research Paper

**Actor**: Research Student  
**Goal**: Index a research paper for semantic search  
**Preconditions**: User has PDF of research paper  
**Postconditions**: Document is indexed and searchable

**Main Flow**:
1. User clicks "Upload Document" button
2. System displays file picker
3. User selects PDF file
4. System validates file type and size
5. System extracts text page by page using PyMuPDF
6. System detects academic sections (Abstract, Method, Results, etc.)
7. System chunks text at sentence boundaries (~1000 chars)
8. System generates embeddings using Sentence-BERT
9. System builds FAISS vector index
10. System displays success message with chunk count
11. System enables query interface

**Alternative Flows**:
- 4a. Invalid file type â†’ Display error, return to step 2
- 5a. PDF corrupted â†’ Display error, request new file
- 8a. Embedding model not downloaded â†’ Download model first

---

#### Use Case 2: Ask METHOD Intent Question

**Actor**: Research Student  
**Goal**: Understand the methodology/algorithm described in the paper  
**Preconditions**: Document is indexed  
**Postconditions**: User receives answer explaining the method

**Main Flow**:
1. User enters query: "How does the compression algorithm work?"
2. System detects intent as METHOD (confidence > 0.7)
3. System generates query embedding
4. System retrieves top-10 chunks via vector similarity
5. System applies METHOD-specific bonuses:
   - +0.15 for "Method" section chunks
   - +0.05 for chunks with algorithmic keywords
6. System re-ranks chunks by final score
7. System selects top-5 chunks
8. System splits chunks into sentences
9. System scores sentences:
   - Bonus for "step", "algorithm", "pipeline"
   - Bonus for numbered lists (1., 2., 3.)
10. System applies token budget (500 tokens)
11. System selects highest-scoring sentences within budget
12. System sends compressed context to LLM
13. System displays answer with method explanation
14. System shows token usage stats (baseline vs compressed)

**Alternative Flows**:
- 2a. Low confidence intent â†’ Use default DEFINITION scoring
- 10a. All sentences exceed budget â†’ Take first sentence only
- 12a. LLM API error â†’ Display error, suggest retry

---

#### Use Case 3: Ask RESULT Intent Question

**Actor**: Research Student  
**Goal**: Find specific performance metrics or results  
**Preconditions**: Document is indexed  
**Postconditions**: User receives quantitative results

**Main Flow**:
1. User enters query: "What accuracy did the model achieve?"
2. System detects intent as RESULT (confidence > 0.8)
3. System generates query embedding
4. System retrieves chunks via vector similarity
5. System applies RESULT-specific bonuses:
   - +0.15 for "Results" section chunks
   - +0.10 for chunks containing numbers
   - +0.05 for chunks with % symbol
6. System re-ranks chunks
7. System splits into sentences
8. System scores sentences:
   - +0.2 for sentences with numbers
   - +0.15 for sentences with %
   - +0.2 for metric keywords (accuracy, F1, precision)
9. System applies token budget
10. System generates answer with specific metrics
11. System displays answer with citations (page numbers)

**Alternative Flows**:
- 9a. No numeric sentences found â†’ Return definition instead
- 10a. Multiple contradicting results â†’ Return all with page citations

---

#### Use Case 4: Ask API_USAGE Intent Question

**Actor**: API Developer  
**Goal**: Learn how to use a specific function  
**Preconditions**: API documentation is indexed  
**Postconditions**: User receives usage examples and parameter info

**Main Flow**:
1. User enters query: "How do I use the authenticate() function?"
2. System detects intent as API_USAGE (confidence > 0.85)
3. System retrieves chunks
4. System scores sentences with code symbols:
   - +0.25 for sentences with (, ), = symbols
   - +0.15 for "parameter", "argument", "return"
5. System prioritizes code snippets and examples
6. System applies budget
7. System generates answer with usage example
8. System displays formatted code blocks

---

#### Use Case 5: Compare Baseline vs Adaptive RAG

**Actor**: System Evaluator  
**Goal**: Measure token reduction and answer quality  
**Preconditions**: Document indexed, test queries prepared  
**Postconditions**: Metrics collected for both approaches

**Main Flow**:
1. Evaluator runs integration test script
2. For each test query:
   a. Run baseline RAG (concatenate top-5 chunks)
   b. Count baseline tokens
   c. Run adaptive compression
   d. Count compressed tokens
   e. Calculate compression ratio
   f. Generate answers with both methods
   g. Compare answer quality
3. System displays comparison table
4. System calculates aggregate metrics

---

## 8. Class Design

### Class Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                   PDFExtractor                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + extract_text_from_pdf(pdf_path: str): list                â”‚
â”‚   Returns: [{"page": int, "text": str}]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                  SectionDetector                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + detect_sections(pages_data: list): list                   â”‚
â”‚ - _detect_section_header(text: str, patterns: list): str    â”‚
â”‚   Returns: [{"page": int, "section": str, "text": str}]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                      Chunker                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + chunk_documents(pages: list, chunk_size: int): list       â”‚
â”‚ - _split_text_into_chunks(text: str, size: int): list       â”‚
â”‚ - _split_into_sentences(text: str): list                    â”‚
â”‚   Returns: [{"chunk_id": int, "page": int,                  â”‚
â”‚              "section": str, "text": str}]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                      Embedder                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - model: SentenceTransformer                                â”‚
â”‚ + generate_embeddings(chunks: list, model_name: str): list  â”‚
â”‚   Returns: chunks + {"embedding": list[float]}              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                    VectorStore                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + build_faiss_index(chunks: list): (Index, list)            â”‚
â”‚ + search_index(index: Index, metadata: list,                â”‚
â”‚                query_emb: list, top_k: int): list            â”‚
â”‚   Returns: [{"chunk_id": int, "score": float,               â”‚
â”‚              "rank": int, ...metadata}]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                  IntentDetector                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - intent_patterns: dict[str, list[str]]                     â”‚
â”‚ + detect_intent(query: str): dict                           â”‚
â”‚   Returns: {"intent": str, "confidence": float,             â”‚
â”‚             "method": str}                                   â”‚
â”‚   Intents: METHOD, RESULT, API_USAGE,                       â”‚
â”‚            DEFINITION, COMPARISON                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                     Retriever                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + retrieve_with_intent(query_emb: list, intent_info: dict,  â”‚
â”‚                        index: Index, metadata: list,         â”‚
â”‚                        top_k: int): list                     â”‚
â”‚ + calculate_intent_bonus(text: str, section: str,           â”‚
â”‚                          intent: str): float                 â”‚
â”‚   Returns: [{"chunk_id": int, "similarity_score": float,    â”‚
â”‚              "intent_bonus": float, "final_score": float,   â”‚
â”‚              "rank": int, ...metadata}]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                  EvidenceSelector                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + select_evidence(chunks: list, intent_info: dict,          â”‚
â”‚                   top_k: int): list                          â”‚
â”‚ + score_sentence(sentence: str, intent: str): float         â”‚
â”‚ + split_into_sentences(text: str): list                     â”‚
â”‚   Returns: [{"sentence": str, "page": int,                  â”‚
â”‚              "section": str, "score": float}]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                   BudgetManager                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + apply_budget(evidence: list, token_limit: int): dict      â”‚
â”‚ + estimate_tokens(text: str): int                           â”‚
â”‚   Returns: {"selected_evidence": list,                      â”‚
â”‚             "tokens_used": int, "num_sentences": int}        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                   Compressor                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + compress_context(query_emb: list, intent_info: dict,      â”‚
â”‚                    index: Index, metadata: list,             â”‚
â”‚                    top_k: int, token_limit: int): dict       â”‚
â”‚   Orchestrates: Retrieval â†’ Evidence Selection â†’ Budget     â”‚
â”‚   Returns: {"compressed_context": str,                      â”‚
â”‚             "selected_evidence": list,                       â”‚
â”‚             "tokens_used": int, "num_sentences": int}        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                     LLMWrapper                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - client: genai.Client                                      â”‚
â”‚ - api_key: str (from env)                                   â”‚
â”‚ + generate_answer(context: str, query: str): str            â”‚
â”‚   Model: gemini-2.5-flash                                   â”‚
â”‚   Temperature: 0.2                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                  AdaptiveRAG                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + run_adaptive_rag(query: str, index: Index,                â”‚
â”‚                    metadata: list, top_k: int,               â”‚
â”‚                    token_limit: int): dict                   â”‚
â”‚   Pipeline: Intent â†’ Embed â†’ Compress â†’ Generate            â”‚
â”‚   Returns: {"query": str, "intent": dict, "answer": str,    â”‚
â”‚             "compressed_context": str, "tokens_used": int}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Â«moduleÂ»                                â”‚
â”‚                   BaselineRAG                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + run_baseline_rag(query: str, index: Index,                â”‚
â”‚                    metadata: list, top_k: int): dict         â”‚
â”‚   Pipeline: Embed â†’ Retrieve â†’ Concatenate â†’ Generate       â”‚
â”‚   Returns: {"query": str, "answer": str, "context": str,    â”‚
â”‚             "token_count": int}                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Class Relationships

```
PDFExtractor â”€â”€â–º SectionDetector â”€â”€â–º Chunker â”€â”€â–º Embedder â”€â”€â–º VectorStore
                                                                    â”‚
                                                                    â”‚
IntentDetector â”€â”€â–º Retriever â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
              EvidenceSelector â”€â”€â–º BudgetManager â”€â”€â–º Compressor
                                                          â”‚
                                                          â–¼
                                                     LLMWrapper
                                                          â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â–¼                                           â–¼
                              AdaptiveRAG                                 BaselineRAG
```

### Key Design Patterns

1. **Functional Programming Pattern**: Most modules are pure functions without state
2. **Pipeline Pattern**: Sequential processing stages with clear data transformations
3. **Strategy Pattern**: Different compression strategies based on detected intent
4. **Facade Pattern**: `AdaptiveRAG` and `BaselineRAG` provide simple interfaces to complex pipelines

---

## 9. Sequence Diagrams

### Sequence Diagram 1: Document Indexing Process

```
User          UI          PDFExtractor   SectionDetector   Chunker    Embedder    VectorStore
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚â”€Upload PDFâ”€>â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚â”€â”€extract_textâ”€>â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚<â”€â”€pages_dataâ”€â”€â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚â”€â”€â”€detect_sectionsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚<â”€â”€pages_with_sectionsâ”€â”€â”€â”€â”€â”€â”€â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚â”€â”€â”€chunk_documentsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚<â”€â”€â”€chunksâ”€â”€â”€â”€â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚â”€â”€â”€generate_embeddingsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚<â”€chunks_with_embsâ”€â”€â”€â”€â”€â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚â”€â”€â”€build_faiss_indexâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚<â”€(index,   â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚  metadata)â”€â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚             â”‚<â”€â”€Success: "Document indexed with X chunks"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚             â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚<â”€Displayâ”€â”€â”€â”€â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
 â”‚  Message    â”‚                â”‚               â”‚             â”‚          â”‚            â”‚
```

### Sequence Diagram 2: Query Processing with Adaptive Compression

```
User    UI    IntentDetector  Embedder  Retriever  EvidenceSelector  BudgetMgr  Compressor  LLM
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚â”€Queryâ”€>â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚â”€detectâ”€â”€â”€â”€>â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚  intent    â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚<â”€intent_infoâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚  {intent: "RESULT",   â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚   confidence: 0.85}   â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚â”€embed_queryâ”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚<â”€query_embeddingâ”€â”€â”€â”€â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€compress_contextâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚<â”€retrieve_with_intentâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚  (query_emb, intent_info, index)        â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚â”€â”€search_indexâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚  (top_k=10)  â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚<â”€retrieved_chunksâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚â”€â”€calculate_intent_bonusâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚  (RESULT intent: boost chunks with %)  â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚<â”€reranked_chunksâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚<â”€â”€â”€â”€select_evidenceâ”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚  (chunks, intent_info)  â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚â”€â”€split_into_sentencesâ”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚â”€â”€score_sentenceâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚  (RESULT: +0.2 for %)   â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚<â”€scored_evidenceâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚<â”€â”€apply_budgetâ”€â”€â”€â”€â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚  (token_limit=500)â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚â”€â”€estimate_tokensâ”€â”€â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚â”€â”€greedy_selectâ”€â”€â”€â”€â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚  (until budget)   â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚<â”€selected_evidenceâ”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚  {tokens: 485}    â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€compressed_contextâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€generate_answerâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚<â”€â”€â”€API â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚  call  â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚ (Gemini)
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚<â”€answerâ”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚       â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€resultâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚       â”‚  {answer, tokens_used: 485, compression_ratio: 52%}           â”‚           â”‚        â”‚
 â”‚       â”‚           â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
 â”‚<â”€Display Resultâ”€â”€â”‚           â”‚          â”‚              â”‚             â”‚           â”‚        â”‚
```

### Sequence Diagram 3: Baseline RAG (for Comparison)

```
User    UI    Embedder  VectorStore  BaselineRAG    LLM
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚â”€Queryâ”€>â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚â”€â”€â”€â”€â”€â”€run_baseline_ragâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚<â”€embed_queryâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚<â”€â”€â”€query_embeddingâ”€â”€â”€â”€â”€â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚<â”€search_index(top_k=5)â”€â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚â”€retrieved_chunksâ”€â”€â”€â”€â”€â”€â”€>â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚â”€â”€concatenate_chunks
 â”‚       â”‚        â”‚          â”‚            â”‚  (join with newlines)
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚â”€â”€count_tokensâ”€â”€â”€â”€>â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚  (baseline: 1200) â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚â”€â”€generate_answerâ”€>â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚<â”€answerâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚       â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€resultâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚
 â”‚       â”‚  {answer, token_count: 1200}   â”‚           â”‚
 â”‚       â”‚        â”‚          â”‚            â”‚           â”‚
 â”‚<â”€Displayâ”€â”€â”€â”€â”€â”‚          â”‚            â”‚           â”‚
 â”‚  Result      â”‚          â”‚            â”‚           â”‚
```

---

## 10. Technology Stack Justification

### Core Technologies

#### 1. **Python 3.9+**
**Why Chosen**:
- Rich ML/AI ecosystem (transformers, FAISS, NumPy)
- Rapid prototyping for research projects
- Strong community support for NLP tasks
- Easy integration with LLM APIs

**Alternatives Considered**:
- JavaScript/TypeScript: Lacks mature ML libraries
- Java: More verbose, slower iteration
- R: Not suitable for production applications

---

#### 2. **Streamlit**
**Why Chosen**:
- Fastest way to build ML/AI web interfaces
- Pure Python (no HTML/CSS/JS required)
- Built-in widgets for file upload, forms
- Real-time updates with minimal code
- Perfect for research demos and prototypes

**Alternatives Considered**:
- Flask/FastAPI + React: Much more complex, slower development
- Gradio: Less customizable than Streamlit
- Jupyter Notebooks: Not suitable for end-user applications

---

#### 3. **Sentence-BERT (all-MiniLM-L6-v2)**
**Why Chosen**:
- **Fast**: 384-dimensional embeddings (vs 768 or 1536)
- **Accurate**: Trained on semantic similarity tasks
- **CPU-friendly**: Can run without GPU
- **Small**: ~80MB model size
- **Proven**: 14M+ downloads, widely used in RAG systems

**Alternatives Considered**:
- OpenAI text-embedding-ada-002: Expensive ($0.0001/1K tokens), API dependency
- BERT base: Too slow, requires GPU
- Universal Sentence Encoder: Larger model, similar performance

---

#### 4. **FAISS (Facebook AI Similarity Search)**
**Why Chosen**:
- **Exact search**: IndexFlatL2 for perfect recall
- **In-memory**: Microsecond query latency
- **Scalable**: Can handle millions of vectors
- **CPU-optimized**: SIMD acceleration
- **Battle-tested**: Used by Meta, Spotify, Shopify

**Alternatives Considered**:
- ChromaDB: Heavier dependency, persistence overhead
- Pinecone: Cloud-only, recurring costs
- Elasticsearch: Overkill for vector search, complex setup

---

#### 5. **Google Gemini 2.5 Flash**
**Why Chosen**:
- **Cost-effective**: Cheaper than GPT-4
- **Fast**: Lower latency than GPT-3.5
- **Context window**: 1M tokens (huge advantage)
- **Free tier**: Generous for development
- **Multimodal**: Future-ready (images, video)

**Alternatives Considered**:
- OpenAI GPT-4: More expensive, slower
- Anthropic Claude: Limited API access
- Open-source LLMs (Llama, Mistral): Require GPU infrastructure

---

#### 6. **PyMuPDF (fitz)**
**Why Chosen**:
- **Fast**: Written in C, Python bindings
- **Accurate**: Preserves text layout and formatting
- **Lightweight**: Minimal dependencies
- **Page-level extraction**: Fine-grained control

**Alternatives Considered**:
- PyPDF2: Slower, less accurate text extraction
- pdfplumber: Heavier, includes in requirements but not used
- Apache Tika: Java dependency, complex setup

---

### Supporting Libraries

| Library | Purpose | Justification |
|---------|---------|---------------|
| **NumPy** | Numerical operations | Standard for array operations, required by FAISS |
| **PyYAML** | Configuration management | Human-readable config files |
| **python-dotenv** | Environment variables | Secure API key management |
| **pytest** | Testing framework | Industry standard for Python testing |

---

## 11. Scalability & Performance

### Current Performance Characteristics

```
Document Indexing:
â”œâ”€ 100-page PDF: ~10 seconds
â”œâ”€ Embedding generation: ~0.5s per 10 chunks
â””â”€ FAISS index build: <1 second

Query Processing:
â”œâ”€ Intent detection: <10ms (rule-based)
â”œâ”€ Query embedding: ~50ms
â”œâ”€ Vector search (FAISS): <5ms for 1000 vectors
â”œâ”€ Compression: ~100ms (sentence splitting + scoring)
â””â”€ LLM generation: 1-3 seconds (network-dependent)

Total Query Latency: ~2-4 seconds
```

### Scalability Strategies

#### Vertical Scaling (Current Approach)
```
Hardware Requirements by Document Count:

1-10 documents (100-1000 chunks):
â”œâ”€ RAM: 2GB
â”œâ”€ CPU: 2 cores
â””â”€ Storage: 5GB

10-100 documents (1K-10K chunks):
â”œâ”€ RAM: 4GB
â”œâ”€ CPU: 4 cores
â””â”€ Storage: 10GB

100-1000 documents (10K-100K chunks):
â”œâ”€ RAM: 8GB
â”œâ”€ CPU: 8 cores
â””â”€ Storage: 20GB
```

#### Horizontal Scaling (Future Enhancement)
```
For > 1M chunks or multi-tenant deployment:

1. Distributed Vector Store
   â””â”€ Replace FAISS with Weaviate/Qdrant
   â””â”€ Shard index across multiple nodes

2. Load Balancing
   â””â”€ Multiple Streamlit instances behind Nginx
   â””â”€ Session affinity for stateful requests

3. Caching Layer
   â””â”€ Redis for query embeddings
   â””â”€ Reduce repeated LLM calls

4. Async Processing
   â””â”€ Celery for background indexing
   â””â”€ RabbitMQ for task queuing
```

### Performance Optimizations

#### 1. **Batch Processing**
```python
# Instead of embedding one at a time:
for chunk in chunks:
    embedding = model.encode(chunk["text"])  # Slow

# Batch embed all at once:
texts = [c["text"] for c in chunks]
embeddings = model.encode(texts, batch_size=32)  # 5-10x faster
```

#### 2. **Model Caching**
```python
# Load model once at startup, reuse for all queries
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer("all-MiniLM-L6-v2")
```

#### 3. **Index Persistence**
```python
# Save FAISS index to disk, avoid rebuilding
faiss.write_index(index, "data/vector_db/index.faiss")
index = faiss.read_index("data/vector_db/index.faiss")  # Fast load
```

---

## 12. Security Considerations

### Current Security Measures

#### 1. **API Key Protection**
```python
# API keys stored in environment variables, not code
api_key = os.getenv("GOOGLE_API_KEY")

# .env file in .gitignore
# Never commit API keys to repository
```

#### 2. **Input Validation**
```python
# File type validation
allowed_extensions = [".pdf", ".html"]
if not file.name.endswith(tuple(allowed_extensions)):
    raise ValueError("Invalid file type")

# File size limits
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
if file.size > MAX_FILE_SIZE:
    raise ValueError("File too large")
```

#### 3. **Prompt Injection Protection**
```python
# Structured prompts prevent malicious queries
prompt = f"""Answer the question using ONLY the provided context.
If insufficient information, say you cannot answer.

Context:
{context}

Question: {query}"""
```

### Recommended Security Enhancements

#### For Production Deployment:

1. **HTTPS/TLS Encryption**
```nginx
server {
    listen 443 ssl;
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
}
```

2. **Rate Limiting**
```python
from slowapi import Limiter
limiter = Limiter(key_func=get_remote_address)

@limiter.limit("10/minute")
def process_query(query):
    # Prevent abuse
```

3. **Authentication**
```python
# Basic auth for demo apps
import streamlit_authenticator as stauth

authenticator = stauth.Authenticate(...)
name, auth_status, username = authenticator.login()
```

4. **Content Security Policy**
```python
# Prevent XSS attacks in Streamlit
st.set_page_config(
    page_title="Adaptive RAG",
    page_icon="ğŸ”’",
    # Add CSP headers
)
```

---

## 13. Future Enhancements

### Phase 1: Core Improvements (1-2 months)

#### 1. **Advanced Intent Detection**
- Replace rule-based with fine-tuned classifier
- Use BERT-based sequence classification
- Support multi-intent queries
- Confidence calibration

#### 2. **Cross-Encoder Reranking**
```python
from sentence_transformers import CrossEncoder

reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
scores = reranker.predict([(query, chunk) for chunk in chunks])
# More accurate than bi-encoder similarity
```

#### 3. **Citation Extraction**
```python
def extract_citations(answer, evidence):
    # Parse [Page X] references from LLM answer
    # Verify citations actually support claims
    # Highlight cited text in UI
```

#### 4. **Improved Token Counting**
```python
import tiktoken

def count_tokens_accurate(text, model="gpt-3.5-turbo"):
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))
# More accurate than char/4 approximation
```

---

### Phase 2: Feature Expansion (3-4 months)

#### 1. **Multi-Document Support**
- Index multiple papers simultaneously
- Cross-document retrieval
- Document-aware citations
- Comparative analysis queries

#### 2. **Table & Figure Extraction**
```python
# Extract tables from PDFs
import tabula
tables = tabula.read_pdf(pdf_path, pages='all')

# Extract figures
import fitz
for page in doc:
    images = page.get_images()
    # Store image embeddings using CLIP
```

#### 3. **Conversational Context**
```python
# Maintain conversation history
conversation_history = []
conversation_history.append({"role": "user", "content": query})
conversation_history.append({"role": "assistant", "content": answer})

# Use history for follow-up questions
```

#### 4. **Export & Sharing**
- PDF report generation
- Markdown export
- Share via unique URLs
- Citation bibliography

---

### Phase 3: Production Readiness (5-6 months)

#### 1. **Microservices Migration**
```
When to migrate:
- Multiple teams working on different components
- Independent scaling needs emerge
- 10,000+ users
- Multi-tenant requirements

Architecture:
â”œâ”€ Indexing Service (Python + FastAPI)
â”œâ”€ Query Service (Python + FastAPI)
â”œâ”€ Vector Store Service (Weaviate/Qdrant)
â”œâ”€ LLM Gateway (Load balancing, caching)
â””â”€ Web UI (React + Next.js)
```

#### 2. **Monitoring & Observability**
```python
# Application metrics
from prometheus_client import Counter, Histogram

query_counter = Counter('queries_total', 'Total queries processed')
latency_histogram = Histogram('query_latency_seconds', 'Query latency')

# Logging
import structlog
logger = structlog.get_logger()
logger.info("query_processed", 
            intent=intent, 
            tokens_used=tokens, 
            latency_ms=latency)
```

#### 3. **A/B Testing Framework**
```python
# Test different compression strategies
def assign_variant(user_id):
    if hash(user_id) % 2 == 0:
        return "adaptive_v1"
    else:
        return "adaptive_v2"

# Track metrics per variant
variant = assign_variant(user_id)
metrics[variant]['token_reduction'].append(ratio)
metrics[variant]['answer_quality'].append(score)
```

#### 4. **Cost Optimization**
- Implement query caching (Redis)
- Batch LLM requests
- Use cheaper models for simple queries
- Prompt compression techniques

---

### Phase 4: Research Extensions (6+ months)

#### 1. **Learned Compression**
- Train neural compressor (e.g., AutoCompressor)
- End-to-end optimization with reinforcement learning
- Personalized compression based on user feedback

#### 2. **Multimodal RAG**
- Process images, tables, equations
- Vision-language model integration (GPT-4V, Gemini Pro Vision)
- Diagram understanding

#### 3. **Explainability**
- Visualize attention weights
- Show compression decision process
- Interactive evidence exploration

#### 4. **Federated Learning**
- Privacy-preserving RAG
- Local document indexing
- Encrypted search

---

## Conclusion

This architecture document presents a comprehensive design for the Adaptive Context Compression RAG system. The key takeaways:

### âœ… **Architecture Decision**: Modular Monolithic
- **Justified by**: Research focus, sequential pipeline, shared state
- **Benefits**: Simplicity, performance, debuggability
- **Trade-offs**: Future scaling requires refactoring

### ğŸ—ï¸ **System Design**: Layered, Modular, Functional
- **5 core layers**: UI, Orchestration, Services, Data, External
- **Clear separation**: Each component has single responsibility
- **Testable**: Independent modules with well-defined interfaces

### ğŸ”„ **Data Flow**: Sequential Pipeline with Adaptive Branching
- **Linear stages**: Ingestion â†’ Indexing â†’ Retrieval â†’ Compression â†’ Generation
- **Adaptive behavior**: Intent detection drives compression strategy
- **Optimization**: Sentence-level granularity + token budget enforcement

### ğŸ“Š **Performance**: Optimized for Research Workloads
- **Query latency**: 2-4 seconds (acceptable for research demo)
- **Scalability**: Handles 100s of documents, 10K+ chunks
- **Future-ready**: Clear path to horizontal scaling when needed

### ğŸ”’ **Security**: Research-appropriate with Production Path
- **Current**: API key protection, input validation, prompt safety
- **Roadmap**: HTTPS, auth, rate limiting, monitoring

### ğŸš€ **Future Evolution**: Clear Migration Path
- **Phase 1**: Core improvements (better intent detection, reranking)
- **Phase 2**: Feature expansion (multi-doc, tables, conversation)
- **Phase 3**: Production readiness (microservices, monitoring)
- **Phase 4**: Research extensions (learned compression, multimodal)

---

**Document Version**: 1.0  
**Last Updated**: February 27, 2026  
**Authors**: RAG System Development Team  
**Status**: Final - Ready for Review
